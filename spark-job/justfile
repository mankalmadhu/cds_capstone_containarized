set dotenv-load := true
image_name := 'pyspark-sa:dev'
spark_submit_args := 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0'

build:
    docker build -t {{image_name}} .

set positional-arguments
@run *args='':
    docker run -u 0 --mount type=bind,source="$(pwd)",target=/opt/application \
         --mount type=tmpfs,destination=/tmp \
         --entrypoint /opt/spark/bin/spark-submit \
        {{image_name}} --packages {{spark_submit_args}} \
        local:///opt/application/site-packages/spark_driver.py "$@"

shell:
    docker run -it \
    {{image_name}} /opt/spark/bin/pyspark --packages com.amazonaws:aws-java-sdk-bundle:1.11.375,org.apache.hadoop:hadoop-aws:3.2.0

