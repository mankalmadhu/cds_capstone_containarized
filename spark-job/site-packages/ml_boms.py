from enum import Enum, auto
from typing import Optional, List
from datetime import datetime

from pydantic import BaseModel, BaseSettings, Field, validator
from functools import lru_cache


class AutoName(Enum):

    def _generate_next_value_(name, start, count, last_values):
        return name.lower()


class Operations(AutoName):
    fetch = auto()
    clean = auto()
    feature_extract = auto()
    label = auto()
    model_train = auto()
    model_test = auto()
    produce_tweet = auto()
    stream_predict = auto()


class FeatureColumns(str, AutoName):
    lemmatized_text = auto()
    idf_features = auto()
    idf_bi_gram_features = auto()
    cv_features = auto()
    cv_bi_gram_features = auto()
    word2_vec_features = auto()


class MLModels(str, AutoName):
    logistic_regression = auto()
    naive_bayes = auto()
    lstm = auto()


class TaskBaseModel(BaseModel):
    save: Optional[bool] = False
    verbose: Optional[bool] = False


class FetchDataModel(TaskBaseModel):
    fetch_date: Optional[datetime] = None
    total_tweets_to_fetch: Optional[int] = Field(10, ge=10, lt=10000)


class TrainModel(TaskBaseModel):
    ml_model: Optional[MLModels] = MLModels.logistic_regression
    features: Optional[List[FeatureColumns]] = [
        FeatureColumns.word2_vec_features, FeatureColumns.cv_features
    ]


class StreamProduceModel(TaskBaseModel):
    enable_tweet_scraping: Optional[bool] = False


class StreamPredictModel(TaskBaseModel):
    ml_model: Optional[MLModels] = MLModels.logistic_regression


class TwitterCreds(BaseSettings):
    twitter_access_key: str
    twitter_access_secret: str
    twitter_consumer_key: str
    twitter_consumer_secret: str

    class Config:
        env_file = ".env"

    @classmethod
    @lru_cache
    def get_twiiter_creds(cls):
        return TwitterCreds()


class StorageCreds(BaseSettings):
    storage_access: str
    storage_key: str
    storage_secret: str
    storage_endpoint: str

    class Config:
        env_file = ".env"

    @classmethod
    @lru_cache
    def get_storage_creds(cls):
        return StorageCreds()


class KafkaCreds(BaseSettings):
    confluent_bootstrap_server: str
    confluent_api_key: str
    confluent_secret: str
    confluent_streaming_topic: str

    class Config:
        env_file = ".env"

    @classmethod
    @lru_cache
    def get_kafka_creds(cls):
        return KafkaCreds()


class CeleryConfig(BaseSettings):
    celery_broker_url: str
    celery_result_backend: str

    class Config:
        env_file = ".env"

    @classmethod
    @lru_cache
    def get_celery_config(cls):
        return CeleryConfig()


class DataTablePathConfig(BaseSettings):
    hydrated_tweet_table_path: str
    cleaned_tweet_table_path: str
    feature_tweet_table_path: str
    labeled_tweet_table_path: str
    predicted_tweets_path: str

    class Config:
        env_file = ".env"

    @classmethod
    @lru_cache
    def get_data_table_path_config(cls):
        return DataTablePathConfig()


class PipelinePathConfig(BaseSettings):
    tweet_cleaner_pipeline: str
    tweet_feature_pipeline: str
    trained_model_pipeline: str

    class Config:
        env_file = ".env"

    @classmethod
    @lru_cache
    def get_pipeline_path_config(cls):
        return PipelinePathConfig()
