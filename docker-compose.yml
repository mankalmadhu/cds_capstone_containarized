version: '3.8'

services:

  web:
    build: ./web
    ports:
      - 8004:8000
    command: uvicorn main:app --host 0.0.0.0 --reload
    user: root
    volumes:
      - ./web:/usr/src/app
      - ./spark-job:/usr/src/celery
    environment:
      - PYTHONPATH=$$PYTHONPATH:/usr/src/celery/site-packages
    env_file:
      - ./.env
    depends_on:
      - redis
    
  worker:
    build: ./spark-job
    command: "celery --app=site-packages.worker.celery  worker 
             --loglevel=debug --logfile=/tmp/celery.log"
    volumes:
      - ./spark-job:/usr/src/app
    tmpfs:
      - /tmp
    depends_on:
      - web
      - redis
    environment:
      - PYTHONPATH=$$PYTHONPATH:/opt/application/site-packages
    env_file:
      - ./.env


  stream-producer:
    build: ./spark-job
    command: "/opt/spark/bin/spark-submit 
              local:///opt/application/site-packages/spark_driver.py 
              --operation produce_tweet --params '{\"enable_tweet_scraping\" : false}'"
    volumes:
      - ./spark-job:/usr/src/app
    tmpfs:
      - /tmp
    env_file:
      - ./.env
   

  stream-consumer:
    build: ./spark-job
    command: "/opt/spark/bin/spark-submit
             --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0
             local:///opt/application/site-packages/spark_driver.py
             --operation stream_predict --params '{\"verbose\": true, \"save\":false}'"
    volumes:
      - ./spark-job:/usr/src/app
    tmpfs:
      - /tmp
    env_file:
      - ./.env
  

  redis:
    image: redis:6-alpine
 