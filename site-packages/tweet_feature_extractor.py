from pyspark.ml.feature import CountVectorizer
from pyspark.ml.feature import HashingTF, IDF
from pyspark.sql.functions import col, concat_ws
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.feature import NGram
from pyspark.ml.feature import Word2Vec
from pyspark.ml import Pipeline


def extract_features(cleaned_tweet_df):

    hashing = HashingTF(inputCol="lemmatized_text", outputCol="raw_token")

    tf_idf = IDF(inputCol="raw_token", outputCol="idf_features")
    count_vectorizer = CountVectorizer(inputCol="lemmatized_text",
                                       outputCol="cv_features",
                                       minDF=1.0)

    bi_gram = NGram(n=2, inputCol="lemmatized_text", outputCol="bi_grams")
    hashing_bi_gram = HashingTF(inputCol="bi_grams",
                                outputCol="hashing_bi_gram_raw_token")

    count_vectorizer_bigram = CountVectorizer(inputCol="bi_grams",
                                              outputCol="cv_bi_gram_features",
                                              minDF=1.0)

    word2_vectorizer = Word2Vec(vectorSize=50,
                                minCount=0,
                                inputCol="lemmatized_text",
                                outputCol="word2_vec_features")

    feature_assembled_vectors = VectorAssembler(
        inputCols=['word2_vec_features', 'cv_features'],
        outputCol='assembled_features')

    tweet_feature_exraction_pipeline = Pipeline(stages=[
        hashing, tf_idf, count_vectorizer, word2_vectorizer, bi_gram,
        hashing_bi_gram, count_vectorizer_bigram, feature_assembled_vectors
    ])

    tweet_feature_exraction_model = tweet_feature_exraction_pipeline.fit(
        cleaned_tweet_df)

    tweet_feature_extracted_df = tweet_feature_exraction_model.transform(
        cleaned_tweet_df)

    return tweet_feature_exraction_model, tweet_feature_extracted_df
