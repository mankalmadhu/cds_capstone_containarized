from confluent_kafka import Producer
import sys
import os
from time import sleep
import json
from tweet_processor import build_filtered_json_list, build_tweet_search_cursor


def delivery_callback(err, msg):
    if err:
        print('%% Message failed delivery: %s\n' % err)
    else:
        print('%% Message delivered to %s [%d]\n' %
              (msg.topic(), msg.partition()))


def push_to_kafka(data_list):
    confluent_topic_name = 'senti_an'
    confluent_bootstrap_servers = os.environ['confluent_bootstrap_server']
    confluent_api_key = os.environ['confluent_api_key']
    confluent_secret = os.environ['confluent_secret']

    conf = {
        'bootstrap.servers': confluent_bootstrap_servers,
        'session.timeout.ms': 6000,
        'default.topic.config': {
            'auto.offset.reset': 'smallest'
        },
        'security.protocol': 'SASL_SSL',
        'sasl.mechanisms': 'PLAIN',
        'sasl.username': confluent_api_key,
        'sasl.password': confluent_secret
    }
    producer = Producer(**conf)
    producer.poll(1)
    print(f'Pushing {len(data_list)} Elements to kafka')
    producer.produce(confluent_topic_name,
                     json.dumps(data_list).encode('utf-8'),
                     callback=delivery_callback)
    producer.flush()


if __name__ == "__main__":
    from dotenv import load_dotenv

    load_dotenv()
    while True:
        search_words = "COVID19 OR COVID-19 OR coronavirus OR coronavaccine OR coronaoutbreak OR omicron OR booster -filter:retweets"
        date_since = "2021-12-30"
        tweets_cursor = build_tweet_search_cursor(search_words, date_since)
        tweet_list = build_filtered_json_list(tweets_cursor.items(25),
                                              extract_user_details=True)
        if tweet_list:
            push_to_kafka(tweet_list)
        else:
            print('No tweets fetched')
        sleep(30)