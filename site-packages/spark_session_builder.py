from pyspark.sql import SparkSession
from pyspark import SparkConf, SparkFiles
from cachetools import cached, TTLCache
import os
import sys


@cached(TTLCache(maxsize=1, ttl=3600))
def build():
    conf = SparkConf()
    conf.set('spark.hadoop.fs.s3a.aws.credentials.provider',
             'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')
    conf.set('spark.sql.parquet.compression.codec', 'lz4')

    spark = SparkSession.builder.appName("Tweet_Analysis").config(
        conf=conf).getOrCreate()
    sc = spark.sparkContext
    sc.addPyFile(
        SparkFiles.get("/opt/application/site-packages/tweet_cleaner.py"))
    sc.addPyFile(
        SparkFiles.get("/opt/application/site-packages/text_labeler.py"))

    hadoop_config = sc._jsc.hadoopConfiguration()
    hadoop_config.set('fs.s3a.access.key', os.environ['do_storage_key'])
    hadoop_config.set('fs.s3a.secret.key', os.environ['do_storage_secret'])
    hadoop_config.set("fs.s3a.endpoint",
                      "https://sgp1.digitaloceanspaces.com/")

    return spark
